{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":119082,"databundleVersionId":14993753,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:09:36.286531Z","iopub.execute_input":"2026-01-04T01:09:36.287008Z","iopub.status.idle":"2026-01-04T01:09:36.646238Z","shell.execute_reply.started":"2026-01-04T01:09:36.286963Z","shell.execute_reply":"2026-01-04T01:09:36.645405Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s6e1/sample_submission.csv\n/kaggle/input/playground-series-s6e1/train.csv\n/kaggle/input/playground-series-s6e1/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:09:36.647624Z","iopub.execute_input":"2026-01-04T01:09:36.648496Z","iopub.status.idle":"2026-01-04T01:09:37.633046Z","shell.execute_reply.started":"2026-01-04T01:09:36.648462Z","shell.execute_reply":"2026-01-04T01:09:37.632114Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s6e1/train.csv')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s6e1/test.csv')\nbinary_columns = ['internet_access']\nfor col in binary_columns:\n    df_train[col] = df_train[col].map({\"yes\": 1, \"no\": 0})\n    df_test[col]  = df_test[col].map({\"yes\": 1, \"no\": 0})\n\n\ndf_X_train = df_train.drop(columns='exam_score', axis=1)\nY_train = df_train['exam_score']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:13:29.369484Z","iopub.execute_input":"2026-01-04T01:13:29.369878Z","iopub.status.idle":"2026-01-04T01:13:30.811686Z","shell.execute_reply.started":"2026-01-04T01:13:29.369850Z","shell.execute_reply":"2026-01-04T01:13:30.810647Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df_train.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:09:39.603040Z","iopub.execute_input":"2026-01-04T01:09:39.603375Z","iopub.status.idle":"2026-01-04T01:09:39.609757Z","shell.execute_reply.started":"2026-01-04T01:09:39.603333Z","shell.execute_reply":"2026-01-04T01:09:39.608923Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'age', 'gender', 'course', 'study_hours', 'class_attendance',\n       'internet_access', 'sleep_hours', 'sleep_quality', 'study_method',\n       'facility_rating', 'exam_difficulty', 'exam_score'],\n      dtype='object')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"ordinal_columns = ['sleep_quality', 'facility_rating', 'exam_difficulty']\none_hot_columns = ['gender', 'study_method', 'course']\n\n\norden_categorias = [\n    ['poor', 'average', 'good'],\n    ['low', 'medium', 'high'],\n    ['easy', 'moderate','hard']\n]\n\nscaling_features = ['study_hours', 'age', 'class_attendance', 'sleep_hours']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:09:39.610857Z","iopub.execute_input":"2026-01-04T01:09:39.611195Z","iopub.status.idle":"2026-01-04T01:09:39.625371Z","shell.execute_reply.started":"2026-01-04T01:09:39.611168Z","shell.execute_reply":"2026-01-04T01:09:39.624606Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\n\nonehot = OneHotEncoder(handle_unknown='ignore')\nordinal = OrdinalEncoder(categories=orden_categorias)\nscaler = StandardScaler()\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('onehot', onehot, one_hot_columns),\n        ('ordinal', ordinal, ordinal_columns),\n        ('scaler', scaler, scaling_features)\n    ],\n    remainder='passthrough'\n)\n\n\nmodel = LinearRegression()\n\nlr_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model)\n])    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:09:58.526754Z","iopub.execute_input":"2026-01-04T01:09:58.527446Z","iopub.status.idle":"2026-01-04T01:09:58.533713Z","shell.execute_reply.started":"2026-01-04T01:09:58.527413Z","shell.execute_reply":"2026-01-04T01:09:58.532732Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX_train, X_val, y_train, y_val = train_test_split(\n    df_X_train, Y_train, test_size=0.2, random_state=42\n)\n\nlr_pipeline.fit(X_train, y_train)\n\ny_pred = lr_pipeline.predict(X_val)\n\nmse = mean_squared_error(y_val, y_pred)\nrmse = np.sqrt(mse)\n\nprint('MSE: ', mse)\nprint('RMSE',  rmse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:13:41.579647Z","iopub.execute_input":"2026-01-04T01:13:41.580316Z","iopub.status.idle":"2026-01-04T01:13:43.593359Z","shell.execute_reply.started":"2026-01-04T01:13:41.580277Z","shell.execute_reply":"2026-01-04T01:13:43.592501Z"}},"outputs":[{"name":"stdout","text":"MSE:  78.97886390966087\nRMSE 8.887005339801528\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeRegressor\n\nonehot = OneHotEncoder(handle_unknown='ignore')\nordinal = OrdinalEncoder(categories=orden_categorias)\nscaler = StandardScaler()\ndef tree_regressor(max_=15):\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('onehot', onehot, one_hot_columns),\n            ('ordinal', ordinal, ordinal_columns),\n            ('scaler', scaler, scaling_features)\n        ],\n        remainder='passthrough'\n    )\n    \n    \n    model = DecisionTreeRegressor(\n        max_depth=10,\n        min_samples_split=max_,\n        random_state=42\n    )\n    \n    tree_pipeline = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', model)\n    ])    \n\n    tree_pipeline.fit(X_train, y_train)\n\n    y_pred = tree_pipeline.predict(X_val)\n    \n    mse = mean_squared_error(y_val, y_pred)\n    rmse = np.sqrt(mse)\n    \n\n    return mse, rmse","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:35:11.913167Z","iopub.execute_input":"2026-01-04T01:35:11.913478Z","iopub.status.idle":"2026-01-04T01:35:11.920380Z","shell.execute_reply.started":"2026-01-04T01:35:11.913450Z","shell.execute_reply":"2026-01-04T01:35:11.919518Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"max_values= [5,10,15,20, 25]\nsmaller_mse  = 500\nsmaller_param = 0\nfor v in max_values:\n    mse, rmse = tree_regressor(v)\n    \n    print('MSE ' + str(v) + ': ', mse)\n    print('RMSE ' + str(v) + ': ',  rmse)\n\n    if mse < smaller_mse:\n        smaller_mse = mse\n        smaller_param = v\n\nprint('best_param: ', smaller_param)\nprint('best_mse: ', smaller_mse)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:35:12.223496Z","iopub.execute_input":"2026-01-04T01:35:12.224208Z","iopub.status.idle":"2026-01-04T01:35:35.137086Z","shell.execute_reply.started":"2026-01-04T01:35:12.224175Z","shell.execute_reply":"2026-01-04T01:35:35.136327Z"}},"outputs":[{"name":"stdout","text":"MSE 5:  87.5537728600545\nRMSE 5:  9.357017305747302\nMSE 10:  87.5537728600545\nRMSE 10:  9.357017305747302\nMSE 15:  87.5537728600545\nRMSE 15:  9.357017305747302\nMSE 20:  87.5537728600545\nRMSE 20:  9.357017305747302\nMSE 25:  87.5537728600545\nRMSE 25:  9.357017305747302\nbest_param:  5\nbest_mse:  87.5537728600545\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"\nsubmission = pd.DataFrame(list(zip(df_test['id'], y_pred)), columns=['id', 'exam_score'])\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:15:28.752007Z","iopub.execute_input":"2026-01-04T01:15:28.752818Z","iopub.status.idle":"2026-01-04T01:15:29.150515Z","shell.execute_reply.started":"2026-01-04T01:15:28.752784Z","shell.execute_reply":"2026-01-04T01:15:29.149559Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow import keras\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:58:11.409898Z","iopub.execute_input":"2026-01-04T01:58:11.410611Z","iopub.status.idle":"2026-01-04T01:58:11.414692Z","shell.execute_reply.started":"2026-01-04T01:58:11.410578Z","shell.execute_reply":"2026-01-04T01:58:11.413831Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"from tensorflow.keras import layers, regularizers\n\nX_train_deep = preprocessor.fit_transform(X_train)\nX_val_deep = preprocessor.transform(X_val)\n\nmodel = keras.Sequential([\n    Input(shape=(X_train_deep.shape[1],)),\n    Dense(128, activation='relu', kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.001)),\n    Dense(128, activation='relu', kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.001)),\n    Dense(64, activation='relu', kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.001)),\n    Dense(1, kernel_initializer='he_normal')\n\n])\n\n\noptimizer = keras.optimizers.Adam(learning_rate=0.01)\nmodel.compile(optimizer=optimizer, loss='mse', metrics=[keras.metrics.RootMeanSquaredError()])\n\nhistory = model.fit(\n    X_train_deep, y_train,\n    validation_data=(X_val_deep, y_val),\n    epochs=20,\n    batch_size=32,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T03:17:27.148351Z","iopub.execute_input":"2026-01-04T03:17:27.149047Z","iopub.status.idle":"2026-01-04T03:27:56.589909Z","shell.execute_reply.started":"2026-01-04T03:17:27.149007Z","shell.execute_reply":"2026-01-04T03:27:56.589208Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 113472064.0000 - root_mean_squared_error: 6891.4546 - val_loss: 669.1357 - val_root_mean_squared_error: 25.7973\nEpoch 2/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 197537.8125 - root_mean_squared_error: 380.5049 - val_loss: 355.8758 - val_root_mean_squared_error: 18.8588\nEpoch 3/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 764.2640 - root_mean_squared_error: 24.0853 - val_loss: 355.9467 - val_root_mean_squared_error: 18.8628\nEpoch 4/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 653.7467 - root_mean_squared_error: 25.2206 - val_loss: 355.7080 - val_root_mean_squared_error: 18.8591\nEpoch 5/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 374.0772 - root_mean_squared_error: 19.3376 - val_loss: 355.7490 - val_root_mean_squared_error: 18.8611\nEpoch 6/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 359.4658 - root_mean_squared_error: 18.9594 - val_loss: 355.7405 - val_root_mean_squared_error: 18.8610\nEpoch 7/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 357.3631 - root_mean_squared_error: 18.9040 - val_loss: 355.6997 - val_root_mean_squared_error: 18.8600\nEpoch 8/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 357.4219 - root_mean_squared_error: 18.9055 - val_loss: 355.7582 - val_root_mean_squared_error: 18.8616\nEpoch 9/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 357.8295 - root_mean_squared_error: 18.9163 - val_loss: 355.7484 - val_root_mean_squared_error: 18.8613\nEpoch 10/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 357.8319 - root_mean_squared_error: 18.9164 - val_loss: 355.6522 - val_root_mean_squared_error: 18.8587\nEpoch 11/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 358.4879 - root_mean_squared_error: 18.9336 - val_loss: 355.6856 - val_root_mean_squared_error: 18.8596\nEpoch 12/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 358.0905 - root_mean_squared_error: 18.9232 - val_loss: 355.6539 - val_root_mean_squared_error: 18.8588\nEpoch 13/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 358.7736 - root_mean_squared_error: 18.9413 - val_loss: 355.8600 - val_root_mean_squared_error: 18.8643\nEpoch 14/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 358.2796 - root_mean_squared_error: 18.9283 - val_loss: 355.6660 - val_root_mean_squared_error: 18.8591\nEpoch 15/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 357.8307 - root_mean_squared_error: 18.9164 - val_loss: 355.6481 - val_root_mean_squared_error: 18.8586\nEpoch 16/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 357.8099 - root_mean_squared_error: 18.9158 - val_loss: 355.6729 - val_root_mean_squared_error: 18.8593\nEpoch 17/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 356.7202 - root_mean_squared_error: 18.8868 - val_loss: 355.6804 - val_root_mean_squared_error: 18.8595\nEpoch 18/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 357.8367 - root_mean_squared_error: 18.9165 - val_loss: 355.7205 - val_root_mean_squared_error: 18.8606\nEpoch 19/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 358.0611 - root_mean_squared_error: 18.9225 - val_loss: 355.6602 - val_root_mean_squared_error: 18.8590\nEpoch 20/20\n\u001b[1m15750/15750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 357.7137 - root_mean_squared_error: 18.9133 - val_loss: 355.6496 - val_root_mean_squared_error: 18.8587\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}